# Concept
- 错误率:
    通常我们把分类错误的样本数占样本总数的比例称为"错误率(error rate)"
    即如果在m个样本中有a个样本分类错误,则错误率 E = a/m
---
- 精度:
    相应的, 1-a/m称为"精度(accuracy)"
    即"精度=1-错误率"
---
- 误差:
    我们把学习期的实际预测输出和样本的真实输出之间的差异称为"误差(error)"
    学习器在训练集上的误差,称为"训练误差(training error)或经验误差(empirical error)"
    在新样本上的误差,称为"泛化误差(generalization error)"
---
- 过拟合(overfitting):
    当机器学习把训练样本学得"太好"的时候
    很可能已经将训练样本自身的一些特点当作了所有潜在样本都具有的一般性质
    这样就会导致泛化性能下降
---
- 欠拟合(underfitting):
    欠拟合与过拟合相反,恰恰是学得太差了,对训练样本的一般性质未学习好
---

# P,NP,NPC,NP-Hard
    P: 能在多项式时间内解决的问题
---
    NP: 不能在多项式时间内解决或不确定能不能在多项式时间内解决,但能在多项式时间验证的问题
---
    NPC: NP完全问题,所有NP问题在多项式时间内都能约化(Reducibility)到它的NP问题,即解决了此NPC问题,所有NP问题也都得到解决
---
    NP-Hard: NP难问题,所有NP问题在多项式时间内都能约化(Reducibility)到它的问题(不一定是NP问题)
---

# Notes
    欠拟合比较容易克服,例如在决策树学习中扩展分支,在神经网络学习中增加训练轮数等
    而过拟合则很麻烦,过拟合是机器学习面临的关键障碍
    过拟合是无法彻底避免的,只能缓解
    可大致这样理解:
        机器学习面临的问题通常是NP难甚至更难,而有效的学习算法必然是在多项式时间内运行完成
        若可彻底避免过拟合,则通过惊叹误差最小化就能获最优解
        这就意味着,我们构造性地证明了"P=NP"
        因此,只要相信"P!=NP",过拟合就不可避免
---

# Data Preparation
- 留出法(hold-out)
---

- 交叉验证法(cross validation)
    k折交叉验证(k-fold cross validation),k最常用的取值是10,此时称为10折交叉验证
    ps: 10次10折交叉验证法 与 100次留出法 都是进行了100次 训练/测试
---

- 自助法(bootstrapping)
    给定包含m个样本的数据集D,对它进行采样,产生数据集D':
        每次随机从D中挑选一个样本,将其拷贝放入D',然后再将该样本放回初始数据集D中,使得该样本
        在下次采样时仍有可能被采到;这个过程重复执行m次后,我们就得到了包含m个样本的数据集D'
        - 显然,D中有一部分的样本会在D'中出现多次,而另一部分样本不出现
        - 一个简单的估计,样本在m次采样中始终不被采到的概率是$(1-\frac{1}{m})^m$
---

